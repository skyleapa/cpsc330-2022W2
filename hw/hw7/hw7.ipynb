{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 7: Clustering and recommender systems\n",
    "### Associated lectures: Lectures 14 and 15\n",
    "\n",
    "**Due date: Wednesday, March 22, 11:59pm**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a4651888-484b-42a0-95e1-d273e5069205",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe22cb5-f825-4dba-b5e3-3538f4afe703",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8d363-7c31-4381-8a1d-2b2556108916",
   "metadata": {},
   "source": [
    "## Exercise 1: Document clustering toy example <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In lecture 14, we looked at a popular application of clustering: customer segmentation. In this homework, we will work on a toy example of another popular application: [**document clustering**](https://en.wikipedia.org/wiki/Document_clustering). A large amount of unlabeled text data is available out there (e.g., news, recipes, online Q&A), and clustering is a commonly used technique to organize this data in a meaningful way. \n",
    "\n",
    "In this exercise, we will create a toy dataset with sentences from Wikipedia articles and cluster these sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b268-4b0a-4d01-9009-a33312f65d33",
   "metadata": {},
   "source": [
    "### 1.1 Sample sentences from Wikipedia articles\n",
    "rubric={points:2}\n",
    "\n",
    "The code below extracts first sentences of Wikipedia articles on a set of queries. You will need the `wikipedia` package installed in the course environment to run the code below. \n",
    "\n",
    "```\n",
    "conda activate cpsc330\n",
    "conda install -c conda-forge wikipedia\n",
    "```\n",
    "\n",
    "You also need `nltk` library in the course environment. \n",
    "\n",
    "```\n",
    "conda install -c anaconda nltk \n",
    "```        \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following question. \n",
    "\n",
    "1. Given this dataset, how many clusters would you expect a clustering algorithm to identify? How would you manually label these clusters?   \n",
    "\n",
    "> *Note: Feel free to experiment with queries of your choice. But stick to the provided list for the final submission so that it's easier for the TAs when they grade your submission.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374e514b-8b4d-40cf-bcb9-2dbfd4558121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Michelle\n",
      "[nltk_data]     Wang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c71b2eb-caf0-40f7-b7b0-93f1fadbc548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki query</th>\n",
       "      <th>text</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mount Everests</td>\n",
       "      <td>Mount Everest (Nepali: सगरमाथा, romanized: Sagarmāthā; Tibetan: Chomolungma ཇོ་མོ་གླང་མ; Chinese: 珠穆朗玛峰; pinyin: Zhūmùlǎngmǎ Fēng) is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas.</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raspberry</td>\n",
       "      <td>The raspberry is the edible fruit of a multitude of plant species in the genus Rubus of the rose family, most of which are in the subgenus Idaeobatus.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mount Denali</td>\n",
       "      <td>Denali (; also known as Mount McKinley, its former official name) is the highest mountain peak in North America, with a summit elevation of 20,310 feet (6,190 m) above sea level.</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arithmetic</td>\n",
       "      <td>Arithmetic (from Ancient Greek  ἀριθμός (arithmós) 'number', and  τική [τέχνη] (tikḗ [tékhnē]) 'art, craft') is an elementary part of mathematics that consists of the study of the properties of the traditional operations on numbers—addition, subtraction, multiplication, division, exponentiation, and extraction of roots.</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topology</td>\n",
       "      <td>In mathematics, topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseball</td>\n",
       "      <td>Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) through the defender's hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard at each end of the court), while preventing the opposing team from shooting through their own hoop.</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hockey</td>\n",
       "      <td>Hockey is a term used to denote a family of various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mango_fruit</td>\n",
       "      <td>A mango is an edible stone fruit produced by the tropical tree Mangifera indica.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mount Kenya</td>\n",
       "      <td>Mount Kenya (Kikuyu: Kĩrĩnyaga, Kamba, Ki Nyaa) is the highest mountain in Kenya and the second-highest in Africa, after Kilimanjaro.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Football</td>\n",
       "      <td>Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wiki query  \\\n",
       "0  Mount Everests   \n",
       "1  Raspberry        \n",
       "2  Mount Denali     \n",
       "3  Arithmetic       \n",
       "4  Topology         \n",
       "5  Baseball         \n",
       "6  Hockey           \n",
       "7  Mango_fruit      \n",
       "8  Mount Kenya      \n",
       "9  Football         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0  Mount Everest (Nepali: सगरमाथा, romanized: Sagarmāthā; Tibetan: Chomolungma ཇོ་མོ་གླང་མ; Chinese: 珠穆朗玛峰; pinyin: Zhūmùlǎngmǎ Fēng) is Earth's highest mountain above sea level, located in the Mahalangur Himal sub-range of the Himalayas.                                                                                                                                                                                                                        \n",
       "1  The raspberry is the edible fruit of a multitude of plant species in the genus Rubus of the rose family, most of which are in the subgenus Idaeobatus.                                                                                                                                                                                                                                                                                                             \n",
       "2  Denali (; also known as Mount McKinley, its former official name) is the highest mountain peak in North America, with a summit elevation of 20,310 feet (6,190 m) above sea level.                                                                                                                                                                                                                                                                                 \n",
       "3  Arithmetic (from Ancient Greek  ἀριθμός (arithmós) 'number', and  τική [τέχνη] (tikḗ [tékhnē]) 'art, craft') is an elementary part of mathematics that consists of the study of the properties of the traditional operations on numbers—addition, subtraction, multiplication, division, exponentiation, and extraction of roots.                                                                                                                                  \n",
       "4  In mathematics, topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.                                                                                                             \n",
       "5  Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24 cm) in diameter) through the defender's hoop (a basket 18 inches (46 cm) in diameter mounted 10 feet (3.048 m) high to a backboard at each end of the court), while preventing the opposing team from shooting through their own hoop.   \n",
       "6  Hockey is a term used to denote a family of various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium.                                                                                                                                                                                                                                                                    \n",
       "7  A mango is an edible stone fruit produced by the tropical tree Mangifera indica.                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "8  Mount Kenya (Kikuyu: Kĩrĩnyaga, Kamba, Ki Nyaa) is the highest mountain in Kenya and the second-highest in Africa, after Kilimanjaro.                                                                                                                                                                                                                                                                                                                              \n",
       "9  Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "   n_words  \n",
       "0  44       \n",
       "1  30       \n",
       "2  38       \n",
       "3  62       \n",
       "4  68       \n",
       "5  92       \n",
       "6  40       \n",
       "7  15       \n",
       "8  27       \n",
       "9  22       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "queries = [\n",
    "    \"Mount Everests\",\n",
    "    \"Raspberry\",\n",
    "    \"Mount Denali\",\n",
    "    \"Arithmetic\",\n",
    "    \"Topology\",\n",
    "    \"Baseball\",\n",
    "    \"Hockey\",\n",
    "    \"Mango_fruit\",\n",
    "    \"Mount Kenya\",\n",
    "    \"Football\"\n",
    "]\n",
    "\n",
    "wiki_dict = {\"wiki query\": [], \"text\": [], \"n_words\": []}\n",
    "for i in range(len(queries)):\n",
    "    sent = sent_tokenize(wikipedia.page(queries[i]).content)[0]\n",
    "    wiki_dict[\"text\"].append(sent)\n",
    "    wiki_dict[\"n_words\"].append(len(word_tokenize(sent)))\n",
    "    wiki_dict[\"wiki query\"].append(queries[i])\n",
    "\n",
    "wiki_df = pd.DataFrame(wiki_dict)\n",
    "wiki_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506b150-103f-4500-883c-1a85a903061e",
   "metadata": {},
   "source": [
    "**ANS:** When manually reading over the dataset, I would have a cluster for\n",
    "- fruit (Mango_fruit, Raspberry)\n",
    "- sports (Hockey, Football, Baseball)\n",
    "- mountains (Mount Everests, Mount Denali, Mount Kenya)\n",
    "- studies (Arithmetic, Topology)\n",
    "\n",
    "So I would expect a clustering algorithm to identify 4 different clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f82cba-4642-4872-8b15-e49eab897821",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574346ba-94a4-4949-9be3-9ff8ea77488e",
   "metadata": {},
   "source": [
    "### 1.2 `KMeans` with bag-of-words representation \n",
    "rubric={points:10}\n",
    "\n",
    "We have seen that before we pass text to machine learning models, we need to encode it into a numeric representation. So let's encode our toy dataset above (`wiki_df`) to a numeric representation. \n",
    "\n",
    "First, let's try our good old friend: bag-of-words representation. The code below creates dense bag-of-words representation of Wikipedia sentences from question 1.1 using a [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. Run `KMeans` clustering on the transformed data (`bow_sents`) with K = the number of clusters you identified in question 1.1. Examine clustering labels assigned by `KMeans`.\n",
    "2. Repeat after modifying the `CountVectorizer` to ignore words appearing in only one sentence (or document, one row of `wiki_df`).\n",
    "3. Keeping the new `CountVectorizer`, examine clustering labels assigned by `KMeans` under an off-by-1 value of K.\n",
    "4. Briefly describe and analyze the behavoir of `KMeans`. Is `KMeans` doing a reasonable job in clustering the sentences? \n",
    "\n",
    "> You can access cluster label assignments using `labels_` attribute of the clustering object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09628f3b-0608-441a-af31-6f8f33ef46d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>048</th>\n",
       "      <th>10</th>\n",
       "      <th>18</th>\n",
       "      <th>190</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>310</th>\n",
       "      <th>46</th>\n",
       "      <th>addition</th>\n",
       "      <th>africa</th>\n",
       "      <th>...</th>\n",
       "      <th>winter</th>\n",
       "      <th>words</th>\n",
       "      <th>zhūmùlǎngmǎ</th>\n",
       "      <th>λόγος</th>\n",
       "      <th>τέχνη</th>\n",
       "      <th>τική</th>\n",
       "      <th>τόπος</th>\n",
       "      <th>सगरम</th>\n",
       "      <th>ἀριθμός</th>\n",
       "      <th>珠穆朗玛峰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   048  10  18  190  20  24  310  46  addition  africa  ...  winter  words  \\\n",
       "0  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "1  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "2  0    0   0   1    1   0   1    0   0         0       ...  0       0       \n",
       "3  0    0   0   0    0   0   0    0   1         0       ...  0       0       \n",
       "4  0    0   0   0    0   0   0    0   0         0       ...  0       1       \n",
       "5  1    1   1   0    0   1   0    1   0         0       ...  0       0       \n",
       "6  0    0   0   0    0   0   0    0   0         0       ...  1       0       \n",
       "7  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "8  0    0   0   0    0   0   0    0   0         1       ...  0       0       \n",
       "9  0    0   0   0    0   0   0    0   0         0       ...  0       0       \n",
       "\n",
       "   zhūmùlǎngmǎ  λόγος  τέχνη  τική  τόπος  सगरम  ἀριθμός  珠穆朗玛峰  \n",
       "0  1            0      0      0     0      1     0        1      \n",
       "1  0            0      0      0     0      0     0        0      \n",
       "2  0            0      0      0     0      0     0        0      \n",
       "3  0            0      1      1     0      0     1        0      \n",
       "4  0            1      0      0     1      0     0        0      \n",
       "5  0            0      0      0     0      0     0        0      \n",
       "6  0            0      0      0     0      0     0        0      \n",
       "7  0            0      0      0     0      0     0        0      \n",
       "8  0            0      0      0     0      0     0        0      \n",
       "9  0            0      0      0     0      0     0        0      \n",
       "\n",
       "[10 rows x 169 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "bow_sents = vec.fit_transform(wiki_df[\"text\"]).todense()\n",
    "bow_df = pd.DataFrame(\n",
    "    data=bow_sents, columns=vec.get_feature_names_out(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0eaf58d-59b8-456c-a79b-1643596f82b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Wang\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 3, 0, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 \n",
    "kmeans_bow = KMeans(n_clusters=4)\n",
    "kmeans_bow.fit(bow_sents)\n",
    "# wiki_df_cl = wiki_df.copy()\n",
    "# wiki_df_cl[\"cluster\"] = kmeans.predict(bow_sents)\n",
    "# wiki_df_cl\n",
    "\n",
    "# \"Mount Everests\", \"Raspberry\", \"Mount Denali\", \"Arithmetic\", \"Topology\", \"Baseball\", \"Hockey\", \"Mango_fruit\", \"Mount Kenya\", \"Football\"\n",
    "kmeans_bow.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78275d-e487-4f94-8bcf-61869b284c46",
   "metadata": {},
   "source": [
    "Labels:\n",
    "- 0: \"Mount Everests\", \"Raspberry\", \"Mount Denali\", \"Hockey\", \"Mango_fruit\", \"Mount Kenya\", \"Football\"\n",
    "- 1: \"Topology\"\n",
    "- 2: \"Baseball\"\n",
    "- 3: \"Arithmetic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c40d44a-92d0-481f-a9b9-97399485de82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edible</th>\n",
       "      <th>family</th>\n",
       "      <th>feet</th>\n",
       "      <th>fruit</th>\n",
       "      <th>greek</th>\n",
       "      <th>highest</th>\n",
       "      <th>level</th>\n",
       "      <th>mathematics</th>\n",
       "      <th>mount</th>\n",
       "      <th>mountain</th>\n",
       "      <th>properties</th>\n",
       "      <th>sea</th>\n",
       "      <th>sports</th>\n",
       "      <th>study</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edible  family  feet  fruit  greek  highest  level  mathematics  mount  \\\n",
       "0  0       0       0     0      0      1        1      0            1       \n",
       "1  1       1       0     1      0      0        0      0            0       \n",
       "2  0       0       1     0      0      1        1      0            1       \n",
       "3  0       0       0     0      1      0        0      1            0       \n",
       "4  0       0       0     0      1      0        0      1            0       \n",
       "5  0       0       1     0      0      0        0      0            0       \n",
       "6  0       1       0     0      0      0        0      0            0       \n",
       "7  1       0       0     1      0      0        0      0            0       \n",
       "8  0       0       0     0      0      2        0      0            1       \n",
       "9  0       1       0     0      0      0        0      0            0       \n",
       "\n",
       "   mountain  properties  sea  sports  study  team  \n",
       "0  1         0           1    0       0      0     \n",
       "1  0         0           0    0       0      0     \n",
       "2  1         0           1    0       0      0     \n",
       "3  0         1           0    0       1      0     \n",
       "4  0         1           0    0       1      0     \n",
       "5  0         0           0    0       0      2     \n",
       "6  0         0           0    1       0      1     \n",
       "7  0         0           0    0       0      0     \n",
       "8  1         0           0    0       0      0     \n",
       "9  0         0           0    1       0      1     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Repeat after modifying the CountVectorizer to ignore words appearing in only one sentence (or document, one row of wiki_df).\n",
    "\n",
    "# count vectorizer that ignores features which occur in less than 2 documents\n",
    "vec_mod = CountVectorizer(stop_words='english', min_df=2)\n",
    "bow_sents_mod = vec_mod.fit_transform(wiki_df[\"text\"]).todense()\n",
    "bow_df = pd.DataFrame(\n",
    "    data=bow_sents_mod, columns=vec_mod.get_feature_names_out(), index=wiki_df.index\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d9fd04d-080f-471e-a375-7b093ff3d65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Wang\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 3, 3, 2, 0, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_bow_mod = KMeans(n_clusters=4)\n",
    "kmeans_bow_mod.fit(bow_sents_mod)\n",
    "# wiki_df_cl = wiki_df.copy()\n",
    "# wiki_df_cl[\"cluster\"] = kmeans.predict(bow_sents_mod)\n",
    "# wiki_df_cl\n",
    "\n",
    "kmeans_bow_mod.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bbac55-3e79-4b48-b708-1544e80476b2",
   "metadata": {},
   "source": [
    "Labels:\n",
    "- 0: \"Arithmetic\", \"Topology\"\n",
    "- 1: \"Mount Everests\", \"Mount Denali\", \"Mount Kenya\"\n",
    "- 2: \"Baseball\", \"Hockey\", \"Football\"\n",
    "- 3: \"Raspberry\", \"Mango_fruit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77d31959-0e5f-4f74-99bf-f27434750592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Wang\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 2, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Keeping the new CountVectorizer, examine clustering labels assigned by KMeans under an off-by-1 value of K.\n",
    "\n",
    "# using n_clusters 3\n",
    "kmeans_bow_mod_3 = KMeans(n_clusters=3)\n",
    "kmeans_bow_mod_3.fit(bow_sents_mod)\n",
    "# wiki_df_cl = wiki_df.copy()\n",
    "# wiki_df_cl[\"cluster\"] = kmeans.predict(bow_sents_mod)\n",
    "# wiki_df_cl\n",
    "\n",
    "kmeans_bow_mod_3.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b5dd0-7f14-4da9-9018-56bd51f89d86",
   "metadata": {},
   "source": [
    "Labels:\n",
    "- 0: \"Raspberry\", \"Baseball\", \"Hockey\", \"Mango_fruit\", \"Football\"\n",
    "- 1: \"Mount Everests\", \"Mount Denali\", \"Mount Kenya\"\n",
    "- 2: \"Arithmetic\", \"Topology\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee4cd-64db-4200-b3dc-637ee5265c25",
   "metadata": {},
   "source": [
    "4. Briefly describe and analyze the behavior of KMeans. Is KMeans doing a reasonable job in clustering the sentences? \n",
    "\n",
    "**ANS:** Based on the classification labels of the clusters above, KMeans is doing an excellent job in clustering the sentences with the modified CountVectorizer. Before with the original vectorizer, there were too many word representations to correctly cluster the data, as shown with the groups above where most of the data is put in one cluster, and 3 queries are in their own independent cluster which doesn't make much sense. However when we set the vectorizer to only look at words in multiple documents, this drastically improved the clustering as shown with the labels in 2. Finally for 3., KMeans is still making accurate clustering predictions, however since we have reduced the clusters to 3, it is grouping the \"sports\" and \"fruits\" into one cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02261e6d-8195-4248-9c21-5bc520baa89e",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e1b0b-faec-4b86-9e59-b45b3a133e2f",
   "metadata": {},
   "source": [
    "### 1.3 Sentence embedding representation\n",
    "rubric={points:10}\n",
    "\n",
    "Bag-of-words representation is limited in that it does not take into account word ordering and context. There are other richer representations of text, and we are going to use one such representation in this lab. \n",
    "\n",
    "The code below creates an alternative and a more expressive representation of sentences. We will call it *sentence embedding representation*. We'll use [sentence transformer](https://www.sbert.net/index.html) to extract these representations. At this point it's enough to know that this is an alternative representation of text which usually works better than simple bag-of-words representation. We will talk a bit more about embedding representations next week. You need to install `sentence-transformers` in the course conda environment to run the code below. \n",
    "\n",
    "```conda install -c conda-forge sentence-transformers```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the code below and answer the following questions. \n",
    "\n",
    "1. How many dimensions (features associated with each example) are present in this representation? \n",
    "2. Run `KMeans` clustering with sentence embedding representation of text (`emb_sents`) and examine cluster labels. \n",
    "3. How well the sentences are clustered together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a092544-58d7-418d-84ff-2e898ece2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d521fb1c08c4de6ada478363dbdbdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7f4ef/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb3b96855bd43398310f6391fe781b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9af4a612b904486a5a8b4b053b95b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f279f7f4ef/README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a03aaadae4474c80f7cf59ca75828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)79f7f4ef/config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a483a8d07bd438791e8033203c07557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1491798dc7f44623bbe94c44125c0ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)279f7f4ef/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a007cf0ef43f4d13bd5a5cf3127256b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8d9af455b547bba8378826db321de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad9f4e89fb34f1f9bab0c3d64646c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518b7c9dd22746639b3d94c54bd7592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7f4ef/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14848d0b4d174ec0a9911c597a7a57f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0349f18aff4968beae4502c8176fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)279f7f4ef/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c474987a1c148ab87b9b0c16e8e0219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9f7f4ef/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20174ee5-9122-4c10-b112-4a675653fee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.532167</td>\n",
       "      <td>0.219127</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>-0.407121</td>\n",
       "      <td>-0.616050</td>\n",
       "      <td>0.339105</td>\n",
       "      <td>-0.369831</td>\n",
       "      <td>-0.268620</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>-0.063531</td>\n",
       "      <td>0.193070</td>\n",
       "      <td>0.345019</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>-0.018490</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>-0.105441</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.097068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.257144</td>\n",
       "      <td>0.279162</td>\n",
       "      <td>0.222628</td>\n",
       "      <td>0.190509</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.215432</td>\n",
       "      <td>0.124739</td>\n",
       "      <td>0.256541</td>\n",
       "      <td>-0.093520</td>\n",
       "      <td>0.304061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350747</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>0.188898</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.364524</td>\n",
       "      <td>0.270560</td>\n",
       "      <td>0.617305</td>\n",
       "      <td>0.565283</td>\n",
       "      <td>0.068011</td>\n",
       "      <td>0.210108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.153511</td>\n",
       "      <td>0.308003</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.228808</td>\n",
       "      <td>0.145076</td>\n",
       "      <td>-0.189960</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345482</td>\n",
       "      <td>0.149473</td>\n",
       "      <td>-0.128204</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>-0.049316</td>\n",
       "      <td>-0.122242</td>\n",
       "      <td>-0.520354</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.277886</td>\n",
       "      <td>-0.082411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182559</td>\n",
       "      <td>0.174978</td>\n",
       "      <td>-0.142932</td>\n",
       "      <td>0.508398</td>\n",
       "      <td>-0.102793</td>\n",
       "      <td>0.314822</td>\n",
       "      <td>-0.028197</td>\n",
       "      <td>0.235509</td>\n",
       "      <td>0.293719</td>\n",
       "      <td>0.091493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>0.126606</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>0.087272</td>\n",
       "      <td>0.279831</td>\n",
       "      <td>-0.328508</td>\n",
       "      <td>0.157603</td>\n",
       "      <td>0.439282</td>\n",
       "      <td>0.204193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.032420</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.501372</td>\n",
       "      <td>0.442546</td>\n",
       "      <td>0.157427</td>\n",
       "      <td>0.082318</td>\n",
       "      <td>0.287892</td>\n",
       "      <td>0.322356</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267656</td>\n",
       "      <td>-0.337920</td>\n",
       "      <td>0.343272</td>\n",
       "      <td>0.429253</td>\n",
       "      <td>-0.042079</td>\n",
       "      <td>0.466611</td>\n",
       "      <td>-0.574507</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>0.150982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.042878</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>-0.187499</td>\n",
       "      <td>-0.020230</td>\n",
       "      <td>-0.260429</td>\n",
       "      <td>-0.120475</td>\n",
       "      <td>0.067831</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>-0.020178</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178185</td>\n",
       "      <td>-0.003942</td>\n",
       "      <td>0.331447</td>\n",
       "      <td>-0.395468</td>\n",
       "      <td>0.025013</td>\n",
       "      <td>0.082307</td>\n",
       "      <td>-0.561699</td>\n",
       "      <td>0.560588</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>-0.373938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.071380</td>\n",
       "      <td>0.096587</td>\n",
       "      <td>0.055705</td>\n",
       "      <td>-0.525645</td>\n",
       "      <td>0.580350</td>\n",
       "      <td>0.096592</td>\n",
       "      <td>0.441485</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>-0.054260</td>\n",
       "      <td>0.220842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>-0.331446</td>\n",
       "      <td>-0.066380</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>-0.147649</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>-0.095109</td>\n",
       "      <td>0.304423</td>\n",
       "      <td>0.327636</td>\n",
       "      <td>-0.197770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.141320</td>\n",
       "      <td>0.030475</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>-0.219024</td>\n",
       "      <td>-0.277812</td>\n",
       "      <td>0.177240</td>\n",
       "      <td>0.191266</td>\n",
       "      <td>0.252725</td>\n",
       "      <td>-0.035201</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>-0.177959</td>\n",
       "      <td>0.088619</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-0.089657</td>\n",
       "      <td>0.246049</td>\n",
       "      <td>-0.060229</td>\n",
       "      <td>0.500508</td>\n",
       "      <td>-0.045897</td>\n",
       "      <td>-0.046336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.291509</td>\n",
       "      <td>0.554150</td>\n",
       "      <td>0.115631</td>\n",
       "      <td>-0.188635</td>\n",
       "      <td>-0.074476</td>\n",
       "      <td>-0.277101</td>\n",
       "      <td>-0.000275</td>\n",
       "      <td>0.076825</td>\n",
       "      <td>0.199134</td>\n",
       "      <td>0.033997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055575</td>\n",
       "      <td>0.047854</td>\n",
       "      <td>0.214838</td>\n",
       "      <td>-0.086142</td>\n",
       "      <td>0.453633</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>-0.143639</td>\n",
       "      <td>0.167839</td>\n",
       "      <td>-0.151438</td>\n",
       "      <td>-0.076444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.071756</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>-0.071762</td>\n",
       "      <td>0.306060</td>\n",
       "      <td>0.358961</td>\n",
       "      <td>-0.061443</td>\n",
       "      <td>0.167585</td>\n",
       "      <td>0.364614</td>\n",
       "      <td>0.323540</td>\n",
       "      <td>0.141398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404115</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.177493</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.232335</td>\n",
       "      <td>0.260556</td>\n",
       "      <td>0.168149</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>0.121122</td>\n",
       "      <td>0.196881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.532167  0.219127  0.029920 -0.407121 -0.616050  0.339105 -0.369831   \n",
       "1 -0.257144  0.279162  0.222628  0.190509  0.057312  0.215432  0.124739   \n",
       "2 -0.153511  0.308003  0.042989 -0.000983 -0.228808  0.145076 -0.189960   \n",
       "3 -0.182559  0.174978 -0.142932  0.508398 -0.102793  0.314822 -0.028197   \n",
       "4  0.002731  0.032420  0.043655  0.501372  0.442546  0.157427  0.082318   \n",
       "5 -0.042878  0.029167 -0.187499 -0.020230 -0.260429 -0.120475  0.067831   \n",
       "6 -0.071380  0.096587  0.055705 -0.525645  0.580350  0.096592  0.441485   \n",
       "7 -0.141320  0.030475  0.261100 -0.219024 -0.277812  0.177240  0.191266   \n",
       "8 -0.291509  0.554150  0.115631 -0.188635 -0.074476 -0.277101 -0.000275   \n",
       "9 -0.071756  0.133156 -0.071762  0.306060  0.358961 -0.061443  0.167585   \n",
       "\n",
       "          7         8         9  ...       758       759       760       761  \\\n",
       "0 -0.268620  0.284335  0.154874  ...  0.049629 -0.063531  0.193070  0.345019   \n",
       "1  0.256541 -0.093520  0.304061  ... -0.350747 -0.103448  0.188898  0.002680   \n",
       "2  0.006522  0.346580  0.009805  ...  0.345482  0.149473 -0.128204  0.069987   \n",
       "3  0.235509  0.293719  0.091493  ...  0.153091 -0.220330  0.126606  0.091785   \n",
       "4  0.287892  0.322356  0.356958  ...  0.267656 -0.337920  0.343272  0.429253   \n",
       "5  0.296154 -0.020178  0.003125  ...  0.178185 -0.003942  0.331447 -0.395468   \n",
       "6  0.257062 -0.054260  0.220842  ...  0.457613 -0.331446 -0.066380 -0.019426   \n",
       "7  0.252725 -0.035201  0.198338  ...  0.104466 -0.177959  0.088619  0.289035   \n",
       "8  0.076825  0.199134  0.033997  ...  0.055575  0.047854  0.214838 -0.086142   \n",
       "9  0.364614  0.323540  0.141398  ...  0.404115  0.000236  0.177493  0.016162   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0  0.111517 -0.018490  0.062622 -0.105441  0.084189  0.097068  \n",
       "1  0.364524  0.270560  0.617305  0.565283  0.068011  0.210108  \n",
       "2 -0.049316 -0.122242 -0.520354  0.052404  0.277886 -0.082411  \n",
       "3  0.087272  0.279831 -0.328508  0.157603  0.439282  0.204193  \n",
       "4 -0.042079  0.466611 -0.574507  0.004958  0.390041  0.150982  \n",
       "5  0.025013  0.082307 -0.561699  0.560588  0.141633 -0.373938  \n",
       "6 -0.147649  0.034530 -0.095109  0.304423  0.327636 -0.197770  \n",
       "7 -0.089657  0.246049 -0.060229  0.500508 -0.045897 -0.046336  \n",
       "8  0.453633  0.021888 -0.143639  0.167839 -0.151438 -0.076444  \n",
       "9  0.232335  0.260556  0.168149  0.483963  0.121122  0.196881  \n",
       "\n",
       "[10 rows x 768 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sents = embedder.encode(wiki_df[\"text\"])\n",
    "emb_sent_df = pd.DataFrame(emb_sents, index=wiki_df.index)\n",
    "emb_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebba98b0-70ce-42a3-b115-402a664873a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle Wang\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 2, 2, 1, 1, 3, 0, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Run KMeans clustering with sentence embedding representation of text (emb_sents) and examine cluster labels.\n",
    "kmeans_emb = KMeans(n_clusters=4)\n",
    "kmeans_emb.fit(emb_sents)\n",
    "\n",
    "kmeans_emb.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45d725-8090-49df-9eaf-49fb90bcc832",
   "metadata": {},
   "source": [
    "Labels:\n",
    "- 0: \"Arithmetic\", \"Topology\"\n",
    "- 1: \"Mount Everests\", \"Mount Denali\", \"Mount Kenya\"\n",
    "- 2: \"Baseball\", \"Hockey\", \"Football\"\n",
    "- 3: \"Raspberry\", \"Mango_fruit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69f2a3-8c0a-4e4d-b049-9709a4aa731e",
   "metadata": {},
   "source": [
    "**ANS:** In this representation, the dimension is 768 as there are 768 features associated with each example, with 768 columns. The sentences are clustered pretty well together, they give the same results as the BOW representation with min_df=2 and 4 clusters above, which is the clustering I'd expect from my manual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a67c7a-83a4-473a-b710-f31c01f4b6fc",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f7a64-57c5-4511-a2c7-bd319dfdc8b7",
   "metadata": {},
   "source": [
    "### 1.4 DBSCAN with cosine distance  \n",
    "rubric={points:10}\n",
    "\n",
    "Let's try `DBSCAN` on our toy dataset. K-Means is kind of bound to the Euclidean distance because it is based on the notion of means. With `DBSCAN` we can try different distance metrics. In the context of text (sparse data), [cosine similarities](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) or cosine distances tend to work better. Given vectors $u$ and $v$, the **cosine distance** between the vectors is defined as: \n",
    "\n",
    "$$distance_{cosine}(u,v) = 1 - (\\frac{u \\cdot v}{\\left\\lVert u\\right\\rVert_2 \\left\\lVert v\\right\\rVert_2})$$\n",
    "\n",
    "In this exercise, you'll use DBSCAN with cosine distances. \n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Use DBSCAN to cluster our toy data using sentence embedding representation (`emb_sents`) and `metric='cosine'`. \n",
    "2. Briefly comment on the number of clusters identified and the cluster assignment given by the algorithm.\n",
    "\n",
    "> *Note: You will also have to set appropriate values for the hyperparamters `eps` and `min_samples` to get meaningful clusters, as default values for these hyperparameters won't work on this toy dataset. In order to set appropriate value for `eps`, you may want to examine the distances given by [sklearn's `cosine_distance`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_cosine_distances.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e2dba33-239e-40c6-99d2-10a60ad5921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_cosine_distances(emb_sents, emb_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1675d7e6-26ac-4655-8887-de48deb00555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=3, min_samples=2, metric='cosine')\n",
    "dbscan.fit(emb_sents)\n",
    "\n",
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170be22-935c-467a-a9a6-47153bd2b2a1",
   "metadata": {},
   "source": [
    "**ANS:** The number of clusters identified is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f359f90-e90c-4311-adb2-39b6f9a3433c",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30b339-3799-4d4c-b9d5-c0c048243c1f",
   "metadata": {},
   "source": [
    "### 1.5 Visualizing clusters \n",
    "rubric={points:5}\n",
    "\n",
    "One thing we could do with unlabeled data is visualizing it. That said, our data is high dimensional (each example is represented with 768 dimensions) and high-dimensional data is hard to visualize. One way to visualize high-dimensional data is applying dimensionality reduction to get the most important (2 or 3) components of the dataset and visualizing this low-dimensional data. \n",
    "\n",
    "Given data as a `numpy` array and cluster assignments, the `plot_pca_clusters` function below transforms the given data by applying dimensionality reduction and plots the transformed data into corresponding clusters. \n",
    "\n",
    "> *Note: At this point we are using this function only for visualization and you are not expected to understand the PCA part. Feel free to modify the function as you see fit.*\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Call the function `plot_pca_clusters` to visualize the clusters created by the three models above:\n",
    "    - KMeans with bag-of-words representation \n",
    "    - KMeans with sentence embedding representation \n",
    "    - DBSCAN with sentence embedding representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5531c582-11c4-4691-8110-4ccc7342fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Obtain the principal components\n",
    "\n",
    "def plot_pca_clusters(\n",
    "    data,\n",
    "    cluster_labels,\n",
    "    raw_sents=wiki_df[\"text\"],\n",
    "    show_labels=False,\n",
    "    size=100,\n",
    "    title=\"PCA visualization\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Carry out dimensionality reduction using PCA and plot 2-dimensional clusters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : numpy array\n",
    "        data as a numpy array\n",
    "    cluster_labels : list\n",
    "        cluster labels for each row in the dataset\n",
    "    raw_sents : list\n",
    "        the original raw sentences for labeling datapoints\n",
    "    show_labels : boolean\n",
    "        whether you want to show labels for points or not (default: False)\n",
    "    size : int\n",
    "        size of points in the scatterplot\n",
    "    title : str\n",
    "        title for the visualization plot\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    None. Shows the clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_comp = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_comp, columns=[\"pca1\", \"pca2\"])\n",
    "    pca_df[\"cluster\"] = cluster_labels\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(title)\n",
    "    ax = sns.scatterplot(\n",
    "        x=\"pca1\", y=\"pca2\", hue=\"cluster\", data=pca_df, palette=\"tab10\", s=size\n",
    "    )\n",
    "\n",
    "    x = pca_df[\"pca1\"].tolist()\n",
    "    y = pca_df[\"pca2\"].tolist()\n",
    "    if show_labels:\n",
    "        for i, txt in enumerate(raw_sents):\n",
    "            plt.annotate(\" \".join(txt.split()[:10]), (x[i], y[i]))\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4819bf1e-1f9a-4f99-8d0b-40a067c4bd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(data=bow_sents_mod, cluster_labels=kmeans_bow_mod.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "154abf5c-8e50-460d-8f05-36665490f745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(emb_sents, kmeans_emb.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87e7e391-5cfb-4bb3-bca9-c9908fe0d6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pca_clusters(emb_sents, dbscan.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1e1c3-de3b-43ff-a29b-39a14c97dba8",
   "metadata": {},
   "source": [
    "**ANS:** Based on the PCA visualizations, we can see that the clustering models seems to cluster the data effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf74a4-86f7-479f-ac54-4fbd0709b126",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d135d-cf62-4a8c-990d-631ee1662913",
   "metadata": {},
   "source": [
    "## Exercise 2: Movie recommendations\n",
    "<hr>\n",
    "\n",
    "Let's build simple movie recommendation systems using the [MovieLens dataset](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data). The original source of the data is [here](https://grouplens.org/datasets/movielens/), and the structure of the data is described in the [README](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) that comes with it. The code below reads the data as a CSV assuming that it's under `data/ml-100k/` directory under your lab folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41780f0a-8c8d-4baf-8059-cf428dad85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742\n",
       "2  22       377       1       878887116\n",
       "3  244      51        2       880606923\n",
       "4  166      346       1       886397596"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=r_cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "206ca960-e598-48ba-b506-3710e3714047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using these keys later in the starter code\n",
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05efce7-bc1e-4ff1-888c-5053b4f57479",
   "metadata": {},
   "source": [
    "### 2.1 Terminology\n",
    "rubric={points:6}\n",
    "\n",
    "Here is some notation we will be using in this lab. \n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$\n",
    " - $M$: the number of movies, indexed by $m$\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in the utility matrix $Y$\n",
    "    - Thus $|\\mathcal{R}|$ is the total number of ratings\n",
    " - $k$: the number of latent dimensions we use in collaborative filtering\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the utility matrix containing ratings, with a lot of missing entries\n",
    " - $Z$: a matrix whose rows $z_m$ represent the features for movie $m$ (size $M\\times d$).\n",
    " - `train_mat` and `valid_mat`: Utility matrices for train and validation sets, respectively\n",
    " \n",
    "    \n",
    "**Your tasks:**    \n",
    "\n",
    "1. What are the values of $N$ and $M$ in movie ratings data?  \n",
    "2. What would be the shape of the dense utility matrix $Y$? \n",
    "3. What would be the fraction of observed ratings in the utility matrix $Y$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40744eb3-0f31-4237-934e-4694fa82192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(set(ratings[\"user_id\"]))\n",
    "M = len(set(ratings[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76200652-ad16-48fd-ac00-ceb773679a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of observed ratings: 0.063\n"
     ]
    }
   ],
   "source": [
    "print(\"Fraction of observed ratings: %0.3f\" % (len(ratings) / (N * M)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810fb2f-d56c-4869-8741-15da6fb265dc",
   "metadata": {},
   "source": [
    "**ANS:** The shape of the utility matrix Y would be 943 rows since there are 943 users, and 1682 columns since there are 1682 movies or items. The fraction of observed ratings would be 0.063 as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c433a44-37b9-4113-8102-10d918cc84ac",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68b939-60c8-4da8-a32e-384b887656b8",
   "metadata": {},
   "source": [
    "### 2.2 Splitting the data\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the ratings data with `test_size=0.2` and `random_state=42`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "10e9ff6c-c2e2-4d08-a6de-80270219bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ratings.copy()\n",
    "y = ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1526cf-a7e5-425e-b8e5-dd8cadb53a50",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb483ab-ae9a-4d3d-a2d5-be404c422c14",
   "metadata": {},
   "source": [
    "### 2.3 Utility matrix \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Create utility matrices for train and validation sets (similar to how we did in the class). \n",
    "2. Briefly explain the difference between the train and validation utility matrices. \n",
    "\n",
    "> You may use the code from lecture notes with appropriate attributions.  \n",
    "\n",
    "> You won't do it in real life but since our dataset is not that big, create a dense utility matrix in this assignment. You are welcome to try sparse matrix but then you may have to change some started code provided in the later exercises.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9b8d514-615a-4166-b597-eee2e53dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c981750-e9f8-4201-a239-210da37c613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lecture 17\n",
    "def create_Y_from_ratings(\n",
    "    data, N, M, user_mapper, item_mapper, user_key=\"userId\", item_key=\"jokeId\"\n",
    "):  # Function to create a dense utility matrix\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[\"user_id\"]]\n",
    "        m = item_mapper[val[\"movie_id\"]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "192d8a08-c194-45c2-83ca-63156311401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M, user_mapper, item_mapper)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M, user_mapper, item_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052990b6-34e9-4266-aea1-d295bb8fc808",
   "metadata": {},
   "source": [
    "**ANS:** The train utility matrix train_mat has the shape N by M, but only has ratings from X_train with all other ratings missing. The validation utility matrix valid_mat has the shape N by M, but only has ratings from X_valid and all other ratings missing. The difference is with where the data for the matrices come from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce90c62-f51b-4c35-a136-52176cbf8ea3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b8ac2-56be-4193-abda-fea9d4cefb4a",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation and baseline\n",
    "rubric={points:4}\n",
    "\n",
    "To compare different models you build in this homework, let's write a couple of functions for evaluation. \n",
    "- The `error` function returns RMSE.\n",
    "- The `evaluate` function prints the train and validation RMSEs. \n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Briefly explain what exactly we are comparing to evaluate recommender systems. \n",
    "2. Implement the global average baseline, where you predict everything as the global average rating. What's the RMSE of the global average baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "15c3c76a-5d5b-4773-a48c-0f26d5ec5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2653a254-02b0-44b8-8a4a-5eb36b679dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "      <td>3.531262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "          7         8         9  ...      1672      1673      1674      1675  \\\n",
       "0  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "1  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "2  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "3  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "4  3.531262  3.531262  3.531262  ...  3.531262  3.531262  3.531262  3.531262   \n",
       "\n",
       "       1676      1677      1678      1679      1680      1681  \n",
       "0  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "1  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "2  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "3  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "4  3.531262  3.531262  3.531262  3.531262  3.531262  3.531262  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lecture 17\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d1344b4-0601-4ff3-9311-d30032df4162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.13\n",
      "Global average valid RMSE: 1.12\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757ffcd-be92-4cfb-a5a2-14299a6b7a8c",
   "metadata": {},
   "source": [
    "**ANS:** We are comparing the differences between the actual ratings and predicted ratings in our train and validation utility matrices. The RMSE of the global baseline is 1.12 as shown by the above average valid RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6ab6-62ef-4fdd-ba0d-5e7e920154a3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a02d5-bf63-428a-8bac-9fa6f2f38681",
   "metadata": {},
   "source": [
    "### (Optional) 2.5 $k$-nearest neighbours imputation\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Try [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) to fill in the missing entries. Discuss your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaa4e0ba-3048-49e9-89f8-9f30df37f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1643</th>\n",
       "      <th>1644</th>\n",
       "      <th>1645</th>\n",
       "      <th>1646</th>\n",
       "      <th>1647</th>\n",
       "      <th>1648</th>\n",
       "      <th>1649</th>\n",
       "      <th>1650</th>\n",
       "      <th>1651</th>\n",
       "      <th>1652</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>4.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...  1643  1644  1645  \\\n",
       "0    4.0  3.0  4.0  3.7  3.0  3.8  4.0  3.3  5.0  3.0  ...  3.0   3.0   1.0    \n",
       "1    4.0  3.0  3.3  4.1  3.2  4.3  4.4  4.4  4.5  4.1  ...  3.0   3.0   1.0    \n",
       "2    3.8  3.2  2.8  3.1  3.5  3.5  4.0  3.7  3.7  4.3  ...  3.0   3.0   1.0    \n",
       "3    4.1  2.9  3.9  3.1  3.6  3.8  3.3  4.3  4.2  4.2  ...  3.0   3.0   1.0    \n",
       "4    4.0  3.0  3.3  3.8  3.3  4.1  4.0  3.8  3.8  4.1  ...  3.0   3.0   1.0    \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...    \n",
       "938  3.8  3.7  3.7  3.5  4.0  4.1  4.0  3.9  5.0  4.3  ...  3.0   3.0   1.0    \n",
       "939  4.1  3.2  3.6  2.0  3.3  3.6  3.7  4.1  3.0  4.3  ...  3.0   3.0   1.0    \n",
       "940  5.0  3.4  2.9  3.8  3.3  3.6  4.3  3.8  4.5  3.6  ...  3.0   3.0   1.0    \n",
       "941  4.2  3.4  3.6  3.4  4.0  4.0  3.5  4.3  4.0  4.0  ...  3.0   3.0   1.0    \n",
       "942  4.3  5.0  3.2  3.6  3.3  4.0  3.7  4.4  3.0  4.1  ...  3.0   3.0   1.0    \n",
       "\n",
       "     1646  1647  1648  1649  1650  1651  1652  \n",
       "0    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "1    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "2    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "3    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "4    2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "..   ...   ...   ...   ...   ...   ...   ...   \n",
       "938  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "939  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "940  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "941  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "942  2.0   3.0   2.0   1.0   3.0   2.0   3.0   \n",
       "\n",
       "[943 rows x 1653 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)\n",
    "pd.DataFrame(train_mat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7b59440-88f7-4ca0-beae-18937a2f5b87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (943,1653) (943,1682) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_mat_imp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKNN imputer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[87], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(pred_Y, train_mat, valid_mat, model_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(pred_Y, train_mat, valid_mat, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlobal average\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m train RMSE: \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (model_name, \u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mat\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m valid RMSE: \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (model_name, error(pred_Y, valid_mat)))\n",
      "Cell \u001b[1;32mIn[87], line 5\u001b[0m, in \u001b[0;36merror\u001b[1;34m(Y1, Y2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(Y1, Y2):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Returns the root mean squared error (RMSE).\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mnanmean((\u001b[43mY1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY2\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (943,1653) (943,1682) "
     ]
    }
   ],
   "source": [
    "evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567e44d-bf19-4664-b4bf-9dfd4234add2",
   "metadata": {},
   "source": [
    "**ANS:** Based on the global average RMSE values, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65bf17-79e9-4b85-9739-bfc9faf540fa",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d2e8f-e22a-4377-9110-fff8d041289e",
   "metadata": {},
   "source": [
    "### 2.6 Use collaborative filtering with the `surprise` package\n",
    "rubric={points:6}\n",
    "\n",
    "Use the [`surprise`](https://surprise.readthedocs.io/en/stable/) package which has implementation of SVD algorithm for collaborative filtering. You can install it as follows in your conda environment. \n",
    "\n",
    "```\n",
    ">> conda activate cpsc330\n",
    ">> conda install -c conda-forge scikit-surprise\n",
    "or \n",
    ">> pip install scikit-surprise\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out cross-validation using SVD algorithm in the package, similar to how we did it in the lecture on Jester dataset. Report mean RMSE and compare it with global baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "631a26c2-a15a-425a-a875-03820ded9c20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from lecture 17\u001b[39;00m\n\u001b[0;32m      2\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader()\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# I'm being sloppy here. Probably there is a way to create validset from our already split data.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m trainset, validset \u001b[38;5;241m=\u001b[39m surprise\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(\n\u001b[0;32m      7\u001b[0m     data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m  \n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\surprise\\dataset.py:167\u001b[0m, in \u001b[0;36mDataset.load_from_df\u001b[1;34m(cls, df, reader)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_df\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, reader):\n\u001b[0;32m    152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a dataset from a pandas dataframe.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    Use this if you want to use a custom dataset that is stored in a pandas\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m            specified.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasetAutoFolds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\surprise\\dataset.py:262\u001b[0m, in \u001b[0;36mDatasetAutoFolds.__init__\u001b[1;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    265\u001b[0m     ]\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\surprise\\dataset.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_ratings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    263\u001b[0m         (uid, iid, \u001b[38;5;28mfloat\u001b[39m(r), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    265\u001b[0m     ]\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify ratings file or dataframe.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# from lecture 17\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)  # Load the data\n",
    "\n",
    "# I'm being sloppy here. Probably there is a way to create validset from our already split data.\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a69f1858-36c5-4f52-8e9e-3bb28dff9c9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      2\u001b[0m algo \u001b[38;5;241m=\u001b[39m SVD(n_factors\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m algo\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrainset\u001b[49m)\n\u001b[0;32m      4\u001b[0m svd_preds \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mtest(validset)\n\u001b[0;32m      5\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mrmse(svd_preds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63c1f7-82d3-4532-82d7-2d55c8f596d5",
   "metadata": {},
   "source": [
    "**ANS:** The mean RMSE is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044157f-1236-4cb9-8c76-82647f23cc99",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d184a9-7fad-4e34-8fa7-b10443d83911",
   "metadata": {},
   "source": [
    "### 2.7 Clustering based recommendation system?\n",
    "rubric={points:2}\n",
    "\n",
    "How would you apply `K-Means` clustering to build a recommendation systems? What could be challenging with this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43410bc8-d121-4da6-997b-b84cbf419e16",
   "metadata": {},
   "source": [
    "**ANS:** I would use K-Means clustering to get all the rating predictions of the movies for each user. Then I would order the data and recommend the movies with the highest predicted ratings. It could be challenging to keep user retention with predicting not only movies they may like, but also random movies to keep in their interest. There may also be challenges in keeping diversity, since all the movies may end up being in the same genre which could get boring for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab723dc5-4ea6-4c44-ace9-bf345bf8c120",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
